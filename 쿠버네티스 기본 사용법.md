# 쿠버네티스 기본 사용법

- [쿠버네티스 기본 사용법](#쿠버네티스-기본-사용법)
- [](#)
  - [pod를 생성하는 방법](#pod를-생성하는-방법)
    - [create로 파드를 생성해서 run 방식과 비교](#create로-파드를-생성해서-run-방식과-비교)
    - [run과 create deployment로 파드를 생성한 것은 무슨 차이가 있을까요?](#run과-create-deployment로-파드를-생성한-것은-무슨-차이가-있을까요)
  - [디플로이먼트를 생성하고 삭제](#디플로이먼트를-생성하고-삭제)
    - [레플리카셋으로 파드 수 관리하기](#레플리카셋으로-파드-수-관리하기)
  - [3개의 nginx 파드를 디플로이먼트 오브젝트로 만들어 보기](#3개의-nginx-파드를-디플로이먼트-오브젝트로-만들어-보기)
  - [apply로 오브젝트 생성하고 관리하기](#apply로-오브젝트-생성하고-관리하기)
  - [파드의 컨테이너 자동 복구 방법](#파드의-컨테이너-자동-복구-방법)
  - [파드의 동작 보증 기능](#파드의-동작-보증-기능)
    - [파드가 자동 복구가 되면 디플로이먼트에 속한 파드는 어떻게 삭제하나](#파드가-자동-복구가-되면-디플로이먼트에-속한-파드는-어떻게-삭제하나)
  - [노드 자원 보호하기](#노드-자원-보호하기)
  - [노드 유지보수하기](#노드-유지보수하기)
  - [파드 업데이트하고 복구하기](#파드-업데이트하고-복구하기)
    - [파드 업데이트하기](#파드-업데이트하기)
    - [업데이트 실패 시 파드 복구하기](#업데이트-실패-시-파드-복구하기)
    - [특정 시점으로 파드 복구하기](#특정-시점으로-파드-복구하기)

#

## pod를 생성하는 방법

nginx 웹 서버 파드를 생성하고 삭제해 봤습니다. 그런데 방법이 조금 복잡했습니다. 파드를 더 간단하게 생성하는 방법은 없을까요?


kubectl run 명령을 실행하면 쉽게 파드를 생성할 수 있습니다. 다음 명령에서 run 다음에 나오는 nginx는 파드의 이름이고, --image=nginx는 생성할 이미지의 이름입니다.

```
[root@m-k8s ~]# kubectl run nginx-pod --image=nginx
pod/nginx-pod created
```

```
[root@m-k8s ~]# kubectl get pod
NAME        READY   STATUS    RESTARTS   AGE
nginx-pod   1/1     Running   0          45s
```

### create로 파드를 생성해서 run 방식과 비교

create로 파드를 생성하려면 kubectl create에 deployment를 추가해서 실행해야함.
이때 기존 파드 이름인 nginx와 중복을 피하고자 파드의 이름을 dpy-nginx로 지정해 생성합니다.

```
[root@m-k8s ~]# kubectl create deployment dpy-nginx --image=nginx
deployment.apps/dpy-nginx created
```

```
[root@m-k8s ~]# kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
dpy-nginx-c8d778df-grc9b   1/1     Running   0          15s
nginx-pod                  1/1     Running   0          4m29s
```

생성된 파드의 IP를 확인
```
[root@m-k8s ~]# kubectl get pods -o wide
NAME                       READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES
dpy-nginx-c8d778df-grc9b   1/1     Running   0          3m18s   172.16.132.2     w3-k8s   <none>           <none>
nginx-pod                  1/1     Running   0          7m32s   172.16.103.129   w2-k8s   <none>           <none>

```

`curl 172.16.132.2`, `curl 172.16.103.129` 으로 웹 페이지 정보를 받아오는 지 확인.


### run과 create deployment로 파드를 생성한 것은 무슨 차이가 있을까요?

```
run으로 파드를 생성하면 단일 파드 1개만 생성되고 관리됩니다. 그리고 create deployment로 파드를 생성하면 디플로이먼트(Deployment)라는 관리 그룹 내에서 파드가 생성됩니다. 비유를 들자면, run으로 생성한 파드는 초코파이 1개이고, create deployment로 생성한 파드는 초코파이 상자에 들어 있는 초코파이 1개입니다.
```

## 디플로이먼트를 생성하고 삭제

```
[root@m-k8s ~]# kubectl create deployment dpy-hname --image=sysnet4admin/echo-hname
deployment.apps/dpy-hname created
```

```
[root@m-k8s ~]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
dpy-hname-59778b9bb-rlkbg   1/1     Running   0          24s
dpy-nginx-c8d778df-grc9b    1/1     Running   0          10m
nginx-pod                   1/1     Running   0          14m
```

`kubectl delete deployment dpy-hname`

### 레플리카셋으로 파드 수 관리하기

많은 사용자를 대상으로 웹 서비스를 하려면 다수의 파드가 필요한데, 이를 하나씩 생성한다면 매우 비효율적입니다. 그래서 쿠버네티스에서는 다수의 파드를 만드는 레플리카셋 오브젝트를 제공합니다.

```
예를 들어 파드를 3개 만들겠다고 레플리카셋에 선언하면 컨트롤러 매니저와 스케줄러가 워커 노드에 파드 3개를 만들도록 선언합니다. 그러나 레플리카셋은 파드 수를 보장하는 기능만 제공하기 때문에 롤링 업데이트 기능 등이 추가된 디플로이먼트를 사용해 파드 수를 관리하기를 권장합니다.
```

1. 먼저 배포된 파드의 상태를 확인합니다.
```
[root@m-k8s ~]# kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
dpy-nginx-c8d778df-grc9b   1/1     Running   0          14m
nginx-pod                  1/1     Running   0          19m
```

2. nginx-pod를 scale 명령으로 3개로 증가시킵니다. 여기서 --replicas=3은 파드의 수를 3개로 맞추는 옵션입니다.

Error 문
```
[root@m-k8s ~]# kubectl scale pod nginx-pod --replicas=3
Error from server (NotFound): the server could not find the requested resource
```

nginx-pod는 파드로 생성됐기 때문에 디플로이먼트 오브젝트에 속하지 않습니다. 그래서 리소스를 확인할 수 없다는 에러가 발생한 것입니다.


3. 이번에는 디플로이먼트로 생성된 dpy-nginx를 scale 명령과 --replicas=3 옵션으로 파드의 수를 3개로 만듭니다. 

```
[root@m-k8s ~]# kubectl scale deployment dpy-nginx --replicas=3
deployment.apps/dpy-nginx scaled
```

4. scale 명령으로 추가된 2개의 nginx 파드를 확인합니다. 최근에 생성된 파드는 생성 시간(AGE)이 짧습니다.

```
NAME                       READY   STATUS    RESTARTS   AGE
dpy-nginx-c8d778df-6frg6   1/1     Running   0          24s
dpy-nginx-c8d778df-grc9b   1/1     Running   0          16m
dpy-nginx-c8d778df-nrcx7   1/1     Running   0          24s
nginx-pod                  1/1     Running   0          20m
```

기존 디플로이먼트로 생성된 dpy-nginx 외에 추가로 2개가 더 생성 되었다.

5. dpy-nginx의 모든 파드가 정상적으로 워커 노드에 적용되고 IP가 부여됐는지 `kubectl get pods -o wide` 명령으로 확인합니다.

```
[root@m-k8s ~]# kubectl get pods -o wide
NAME                       READY   STATUS    RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES
dpy-nginx-c8d778df-6frg6   1/1     Running   0          88s   172.16.221.132   w1-k8s   <none>           <none>
dpy-nginx-c8d778df-grc9b   1/1     Running   0          17m   172.16.132.2     w3-k8s   <none>           <none>
dpy-nginx-c8d778df-nrcx7   1/1     Running   0          88s   172.16.103.130   w2-k8s   <none>           <none>
nginx-pod                  1/1     Running   0          21m   172.16.103.129   w2-k8s   <none>           <none>
```

6. 다음 진행을 위해 생성한 디플로이먼트 dpy-nginx를 삭제(delete)합니다.
   
```
[root@m-k8s ~]# kubectl delete deployment dpy-nginx
deployment.apps "dpy-nginx" deleted
```

## 3개의 nginx 파드를 디플로이먼트 오브젝트로 만들어 보기

관련 개념 p.51~52

명령어로는 3개의 파드를 가진 디플로이먼트를 만들 수 없으므로 오브젝트 스펙을 작성해 디플로이먼트를 만듭니다.

디플로이먼트의 오브젝트 스펙을 처음부터 만들기는 어려우니 ~/_Book_k8sInfra/ch3/3.2.4 디렉터리의 예제 파일(echo-hname.yaml)을 사용합니다.

```
apiVersion은 오브젝트를 포함하는 API의 버전을 의미합니다. 일반적으로 알파(alpha)와 베타(beta) 버전은 안정적이지 않다고 보지만, 그만큼 풍부한 기능을 갖고 있기도 합니다. 여기서 사용하는 apps/v1은 여러 종류의 kind(오브젝트)를 가지고 있는데, 그중에서 Deployment를 선택해 레플리카셋을 생성합니다. 레플리카셋은 몇 개의 파드를 생성할지 replicas로 결정합니다. 이미지는 sysnet4admin/echo-hname을 사용합니다.
```

1. echo-hname.yaml 파일을 이용해 디플로이먼트를 생성

현재 디플로이먼트는 파드 3개를 생성하도록 replicas에 정의돼 있습니다. 이 부분은 ‘3.2.3 레플리카셋으로 파드 수 관리하기’에 설명돼 있으니 참고하기 바랍니다.

```
[root@m-k8s _Book_k8sInfra]# kubectl create -f ~/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml
deployment.apps/echo-hname created
```

2. 새로 생성된 echo-hname 파드가 3개인지 확인합니다.

```
[root@m-k8s _Book_k8sInfra]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
echo-hname-7894b67f-25vb9   1/1     Running   0          23s
echo-hname-7894b67f-pqdzd   1/1     Running   0          23s
echo-hname-7894b67f-s688f   1/1     Running   0          23s
nginx-pod                   1/1     Running   0          28m
```

3. 디플로이먼트를 생성했으니 이번에는 echo-hname.yaml 파일을 수정해 파드를 6개로 늘리기

`sed -i 's/replicas: 3/replicas: 6/' ~/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml`

4. replicas의 값이 3에서 6으로 변경됐는지 확인합니다.
```
[root@m-k8s _Book_k8sInfra]# cat ~/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml | grep replicas
  replicas: 6
```

5. 변경된 내용을 적용합니다.

```
[root@m-k8s _Book_k8sInfra]# kubectl create -f ~/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml
Error from server (AlreadyExists): error when creating "/root/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml": deployments.apps "echo-hname" already exists
```

‘echo-hname이 이미 존재한다’는 에러 메시지가 나오면서 아무 일도 일어나지 않습니다. 물론 scale 명령으로 파드 수를 늘릴 수 있지만, 파일로 디플로이먼트의 파드 수를 늘리는 것은 불가능할까요? 배포된 오브젝트의 스펙을 변경하고 싶을 때는 어떻게 해야 할까요? 지우고 다시 만드는 방법밖에 없을까요?


## apply로 오브젝트 생성하고 관리하기

- run은 파드를 간단하게 생성하는 매우 편리한 방법입니다. 하지만 run으로는 단일 파드만을 생성할 수 있습니다.

- 그렇다고 create로 디플로이먼트를 생성하면 앞에서 확인한 것처럼 파일의 변경 사항을 바로 적용할 수 없다는 단점이 있습니다.

- 이런 경우를 위해 쿠버네티스는 apply라는 명령어를 제공합니다. 그러면 apply로 오브젝트를 관리해 봅시다.

1. replicas를 6으로 수정한 echo-hname.yaml 파일을 kubectl apply 명령으로 적용합니다.

오브젝트를 처음부터 apply로 생성한 것이 아니어서 경고가 뜹니다.
```
[root@m-k8s _Book_k8sInfra]# kubectl apply -f ~/_Book_k8sInfra/ch3/3.2.4/echo-hname.yaml
Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply
deployment.apps/echo-hname configured
```

2. 명령이 적용된 후에 echo-hname이 6개로 늘어났는지 확인합니다. 특히 AGE를 확인해 최근에 추가된 파드 3개를 확인합니다.

```
[root@m-k8s _Book_k8sInfra]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
echo-hname-7894b67f-25vb9   1/1     Running   0          3m3s
echo-hname-7894b67f-5wcsc   1/1     Running   0          32s
echo-hname-7894b67f-7r4xg   1/1     Running   0          32s
echo-hname-7894b67f-ctl4c   1/1     Running   0          32s
echo-hname-7894b67f-pqdzd   1/1     Running   0          3m3s
echo-hname-7894b67f-s688f   1/1     Running   0          3m3s
nginx-pod                   1/1     Running   0          31m
```

kubectl apply를 사용하면 파일의 변경 사항도 쉽게 적용할 수 있다는 것을 확인했습니다. 앞에서 봤듯이 명령 창명령 창 등에 직접 애드혹(ad-hoc, 일회적 사용)으로 오브젝트를 생성할 때는 create를 사용하고, 변경이 생길 가능성이 있는 복잡한 오브젝트는 파일로 작성한 후 apply로 적용하는 것이 좋습니다.

- 세 가지 명령어 정리 (run, create, apply)
![Alt text](./images/command%20compare.png)


## 파드의 컨테이너 자동 복구 방법

파드의 자동 복구 기술을 셀프 힐링(Self-Healing)이라고 함.
- 제대로 작동하지 않는 컨테이너를 다시 시작하거나 교체해 파드가 정상적으로 작동하게 합니다
  

1. 파드에 접속하려면 파드의 IP를 알아야 합니다. kubectl get pods -o wide 명령으로 접속할 파드의 IP를 확인합니다.
```
[root@m-k8s _Book_k8sInfra]#  kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES
echo-hname-7894b67f-25vb9   1/1     Running   0          7m56s   172.16.132.3     w3-k8s   <none>           <none>
echo-hname-7894b67f-5wcsc   1/1     Running   0          5m25s   172.16.221.134   w1-k8s   <none>           <none>
echo-hname-7894b67f-7r4xg   1/1     Running   0          5m25s   172.16.103.132   w2-k8s   <none>           <none>
echo-hname-7894b67f-ctl4c   1/1     Running   0          5m25s   172.16.132.4     w3-k8s   <none>           <none>
echo-hname-7894b67f-pqdzd   1/1     Running   0          7m56s   172.16.103.131   w2-k8s   <none>           <none>
echo-hname-7894b67f-s688f   1/1     Running   0          7m56s   172.16.221.133   w1-k8s   <none>           <none>
nginx-pod                   1/1     Running   0          36m     172.16.103.129   w2-k8s   <none>           <none>
```

2. kubectl exec 명령을 실행해 파드 컨테이너의 셸(shell)에 접속합니다.

`kubectl exec -it nginx-pod -- /bin/bash`

kubectl exec에서 '- -'의 의미

'--'는 exec에 대한 인자 값을 나누고 싶을 때 사용합니다.

3. 배시 셸에 접속하면 컨테이너에서 구동하는 nginx의 PID(Process ID, 프로세서 식별자)를 확인합니다.

```
root@nginx-pod:/# cat /run/nginx.pid
1
```

4. ls -l 명령으로 프로세스가 생성된 시간을 확인합니다.

```
root@nginx-pod:/# ls -l /run/nginx.pid
-rw-r--r--. 1 root root 2 Nov 10 05:20 /run/nginx.pid
```

5. 슈퍼푸티에서 m-k8s의 터미널을 1개 더 띄우고 nginx-pod의 IP에서 돌아가는 웹 페이지를 1초마다 한 번씩 요청하는 스크립트를 실행

curl에서 요청한 값만 받도록 --silent 옵션을 추가합니다. 이 스크립트로 nginx의 상태도 체크합니다.

`i=1; while true; do sleep 1; echo $((i++)) `curl --silent 172.16.103.129 | grep title` ; done`

6. 배시 셸에서 nginx 프로세서인 PID 1번을 kill 명령으로 종료합니다.

```
root@nginx-pod:/# kill 1
root@nginx-pod:/# command terminated with exit code 137
```

7. 추가한 터미널에서 1초마다 nginx 웹 페이지를 받아오는 스크립트가 잘 작동하는지 확인하고, 자동으로 다시 복구되는지도 함께 확인합니다.

중간에 끊겼다가 다시 복구되는 것을 확인 할 수 있다.
```
30 <title>Welcome to nginx!</title>
31 <title>Welcome to nginx!</title>
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47 <title>Welcome to nginx!</title>
48 <title>Welcome to nginx!</title>
49 <title>Welcome to nginx!</title>
50 <title>Welcome to nginx!</title>
```


8. nginx 웹 페이지가 복구되는 것을 확인한 후에 다시 nginx-pod에 접속합니다.

nginx.pid가 생성된 시간으로 새로 생성된 프로세스인지 확인
```
root@nginx-pod:/# ls -l /run/nginx.pid
-rw-r--r--. 1 root root 2 Nov 10 06:05 /run/nginx.pid
```

nginx 프로세스는 몇 초만에 종료되고 바로 다시 실행되므로 생성 시간을 확인하기가 어려울 수 있습니다. 만약 정확하게 확인하지 못했다면 원래 터미널 창에서 다시 한 번 kill 1을 실행해 시간을 확인해 봅시다.


## 파드의 동작 보증 기능

1. 현재 어떤 파드들이 있는지 먼저 확인

`kubectl get pods`
```
[root@m-k8s ~]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
echo-hname-7894b67f-25vb9   1/1     Running   0          2d22h
echo-hname-7894b67f-5wcsc   1/1     Running   0          2d22h
echo-hname-7894b67f-7r4xg   1/1     Running   1          2d22h
echo-hname-7894b67f-ctl4c   1/1     Running   0          2d22h
echo-hname-7894b67f-pqdzd   1/1     Running   1          2d22h
echo-hname-7894b67f-s688f   1/1     Running   0          2d22h
nginx-pod                   1/1     Running   3          2d23h
```


2. 파드에 문제가 발생하는 상황을 만들기 위해 앞에서 생성한 파드를 삭제
`kubectl delete pods nginx-pod`

```
[root@m-k8s ~]#  kubectl delete pods nginx-pod
pod "nginx-pod" deleted
```

3. 파드의 동작을 보증하려면 어떤 조건이 필요합니다. 어떤 조건인지 확인하기 위해 다른 파드도 삭제해 서로 비교
가장 위에 있던 `echo-hname-7894b67f-25vb9` 삭제.
`kubectl delete pods echo-hname-7894b67f-25vb9`

```
[root@m-k8s ~]# kubectl delete pods echo-hname-7894b67f-25vb9
pod "echo-hname-7894b67f-25vb9" deleted
```

4. 삭제가 잘 됐는지 kubectl get pods로 확인
`kubectl get pods`
```
NAME                        READY   STATUS    RESTARTS   AGE
echo-hname-7894b67f-5wcsc   1/1     Running   0          2d22h
echo-hname-7894b67f-7r4xg   1/1     Running   1          2d22h
echo-hname-7894b67f-ctl4c   1/1     Running   0          2d22h
echo-hname-7894b67f-l42jc   1/1     Running   0          53s
echo-hname-7894b67f-pqdzd   1/1     Running   1          2d22h
echo-hname-7894b67f-s688f   1/1     Running   0          2d22h
```

삭제한 pod name은 없고 새로운 pod가 생성됨.  

파드의 동작을 보장하기 위한 조건임.


### 파드가 자동 복구가 되면 디플로이먼트에 속한 파드는 어떻게 삭제하나

5. 디플로이먼트에 속한 파드는 상위 디플로이먼트를 삭제해야 파드가 삭제됨.
`kubectl delete deployment echo-hname`

```
[root@m-k8s ~]# kubectl delete deployment echo-hname
deployment.apps "echo-hname" deleted
```

6. 디플로이먼트를 삭제한 후에 배포된 파드가 남아 있는지 확인
`kubectl get pods`
```
[root@m-k8s ~]#  kubectl get pods
No resources found in default namespace.
```

## 노드 자원 보호하기

여러 가지 상황에서도 쿠버네티스는 파드를 안정적으로 작동하도록 관리한다.

노드는 어떤 식으로 관리할까?


최근에 몇 차례 문제가 생긴 노드에 파드를 할당하면 문제가 생길 가능성이 높습니다. 하지만 어쩔 수 없이 해당 노드를 사용해야 한다면 어떻게 할까요? 이런 경우에는 영향도가 적은 파드를 할당해 일정 기간 사용하면서 모니터링해야 합니다. 즉, 노드에 문제가 생기더라도 파드의 문제를 최소화해야 합니다. 하지만 쿠버네티스는 모든 노드에 균등하게 파드를 할당하려고 합니다. 그렇다면 어떻게 문제가 생길 가능성이 있는 노드라는 것을 쿠버네티스에 알려줄까


쿠버네티스에서는 이런 경우에 cordon 기능을 사용

1. 현재 배포된 파드가 없기 때문에 echo-hname.yaml을 적용해(apply) 파드를 생성

```
[root@m-k8s ~]# kubectl apply -f ~/_Book_k8sInfra/ch3/3.2.8/echo-hname.yaml
deployment.apps/echo-hname created
```

2. scale 명령으로 배포한 파드를 9개로 늘립니다.

```
[root@m-k8s ~]# kubectl scale deployment echo-hname --replicas=9
deployment.apps/echo-hname scaled
```

3. 배포된 9개의 파드가 제대로 작동하는지, IP 할당이 잘 됐는지, 각 노드로 공평하게 배분됐는지를 확인

`kubectl get pods -o wide` 대신에 `kubectl get pods -o=custom-columns`를 사용

-o는 output을 의미, custom-columns는 사용자가 임의로 구성할 수 있는 열을 의미


명령에서 NAME, IP, STATUS, NODE는 열의 제목이고, 콜론(:) 뒤에 내용 값인 .metadata.name, .status.podIP, .status.phase, .spec.nodeName을 넣고 콤마(,)로 구분


`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`

```
NAME                        IP               STATUS    NODE
echo-hname-7894b67f-2pvdj   172.16.132.8     Running   w3-k8s
echo-hname-7894b67f-6vrdv   172.16.132.6     Running   w3-k8s
echo-hname-7894b67f-8bzq2   172.16.221.135   Running   w1-k8s
echo-hname-7894b67f-9wpxj   172.16.103.138   Running   w2-k8s
echo-hname-7894b67f-dzhd6   172.16.103.136   Running   w2-k8s
echo-hname-7894b67f-fdkr8   172.16.221.136   Running   w1-k8s
echo-hname-7894b67f-lgkrc   172.16.132.7     Running   w3-k8s
echo-hname-7894b67f-rg9qb   172.16.103.137   Running   w2-k8s
echo-hname-7894b67f-s88lp   172.16.221.137   Running   w1-k8s
```

4. scale로 파드의 수를 3개로 줄입니다.
```
[root@m-k8s ~]# kubectl scale deployment echo-hname --replicas=3
deployment.apps/echo-hname scaled
```

5. 각 노드에 파드가 1개씩만 남았는지 확인합니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`
```
NAME                        IP               STATUS    NODE
echo-hname-7894b67f-6vrdv   172.16.132.6     Running   w3-k8s
echo-hname-7894b67f-8bzq2   172.16.221.135   Running   w1-k8s
echo-hname-7894b67f-dzhd6   172.16.103.136   Running   w2-k8s
```

6. 만약 w3-k8s 노드에서 문제가 자주 발생한다면 현재 상태를 보존해야 합니다. w3-k8s 노드에 cordon 명령을 실행합니다.

`kubectl cordon w3-k8s`
```
[root@m-k8s ~]# kubectl cordon w3-k8s
node/w3-k8s cordoned
```

7. `kubectl get nodes` 명령을 실행해 cordon 명령이 제대로 적용됐는지 확인합니다.

```
[root@m-k8s ~]# kubectl get nodes
NAME     STATUS                     ROLES    AGE     VERSION
m-k8s    Ready                      master   3d23h   v1.18.4
w1-k8s   Ready                      <none>   3d23h   v1.18.4
w2-k8s   Ready                      <none>   3d23h   v1.18.4
w3-k8s   Ready,SchedulingDisabled   <none>   3d23h   v1.18.4
```

w3-k8s가 더 이상 파드가 할당되지 않는 상태로 변경됐습니다

cordon 명령을 실행하면 해당 노드에 파드가 할당되지 않게 스케줄되지 않는 상태(SchedulingDisabled)라는 표시

8. 이 상태에서 파드 수를 9개로 늘립니다.
```
[root@m-k8s ~]# kubectl scale deployment echo-hname --replicas=9
deployment.apps/echo-hname scaled
```

9. 노드에 배포된 파드를 확인합니다. 특히 w3-k8s에 추가로 배포된 파드가 있는지 확인합니다.

```
NAME                        IP               STATUS    NODE
echo-hname-7894b67f-5grdp   172.16.103.140   Running   w2-k8s
echo-hname-7894b67f-6vrdv   172.16.132.6     Running   w3-k8s
echo-hname-7894b67f-8bzq2   172.16.221.135   Running   w1-k8s
echo-hname-7894b67f-b2b4l   172.16.221.138   Running   w1-k8s
echo-hname-7894b67f-dzhd6   172.16.103.136   Running   w2-k8s
echo-hname-7894b67f-h8btv   172.16.221.139   Running   w1-k8s
echo-hname-7894b67f-lx7lv   172.16.103.141   Running   w2-k8s
echo-hname-7894b67f-tbdrs   172.16.221.140   Running   w1-k8s
echo-hname-7894b67f-tccrm   172.16.103.139   Running   w2-k8s
```
w1-k8s는 4개, w2-k8s는 4개지만 w3-k8s는 여전히 1개

cordon 명령을 실행하기 전에는 각각 3개 씩.

10. 이번에는 파드 수를 3개로 줄입니다.
```
[root@m-k8s ~]# kubectl scale deployment echo-hname --replicas=3
deployment.apps/echo-hname scaled
```

11. 각 노드에 할당된 파드 수가 공평하게 1개씩인지 확인합니다.

```
NAME                        IP               STATUS    NODE
echo-hname-7894b67f-6vrdv   172.16.132.6     Running   w3-k8s
echo-hname-7894b67f-8bzq2   172.16.221.135   Running   w1-k8s
echo-hname-7894b67f-dzhd6   172.16.103.136   Running   w2-k8s
```

12. uncordon 명령으로 w3-k8s에 파드가 할당되지 않게 설정했던 것을 해제합니다.

`kubectl uncordon w3-k8s`
```
[root@m-k8s ~]# kubectl uncordon w3-k8s
node/w3-k8s uncordoned
```


13. w3-k8s에 uncordon이 적용됐는지 `kubectl get nodes` 명령으로 확인합니다.

```
[root@m-k8s ~]# kubectl get nodes
NAME     STATUS   ROLES    AGE     VERSION
m-k8s    Ready    master   3d23h   v1.18.4
w1-k8s   Ready    <none>   3d23h   v1.18.4
w2-k8s   Ready    <none>   3d23h   v1.18.4
w3-k8s   Ready    <none>   3d23h   v1.18.4
```

STATUS가 모두 Ready로 변한 것을 알 수 있다.

## 노드 유지보수하기

1. `kubectl drain` 명령을 실행해 유지보수할 노드(w3-k8s)를 파드가 없는 상태로 만듭니다

그런데 이 명령을 실행하면 w3-k8s에서 데몬셋을 지울 수 없어서 명령을 수행할 수 없다고 나옵니다.

```
[root@m-k8s ~]# kubectl drain w3-k8s
node/w3-k8s cordoned
error: unable to drain node "w3-k8s", aborting command...

There are pending nodes to be drained:
 w3-k8s
error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore): kube-system/calico-node-2kgdz, kube-system/kube-proxy-kdjdh
```


여기서 drain이 어떻게 작동하는지 알 수 있습니다. drain은 실제로 파드를 옮기는 것이 아니라 노드에서 파드를 삭제하고 다른 곳에 다시 생성합니다. 앞에서도 설명했지만 파드는 언제라도 삭제할 수 있기 때문에 쿠버네티스에서 대부분 이동은 파드를 지우고 다시 만드는 과정을 의미합니다. 그런데 DaemonSet은 각 노드에 1개만 존재하는 파드라서 drain으로는 삭제할 수 없습니다.


2. 이번에는 drain 명령과 ignore-daemonsets 옵션을 함께 사용합니다

이 옵션을 사용하면 DaemonSet을 무시하고 진행합니다. 경고가 발생하지만 모든 파드가 이동됩니다.

`kubectl drain w3-k8s --ignore-daemonsets`

```
[root@m-k8s ~]# kubectl drain w3-k8s --ignore-daemonsets
node/w3-k8s already cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-2kgdz, kube-system/kube-proxy-kdjdh
evicting pod default/echo-hname-7894b67f-6vrdv
pod/echo-hname-7894b67f-6vrdv evicted
node/w3-k8s evicted
```

3. 노드 w3-k8s에 파드가 없는지 확인합니다. 그리고 옮긴 노드에 파드가 새로 생성돼 파드 이름과 IP가 부여된 것도 확인합니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`

```
NAME                        IP               STATUS    NODE
echo-hname-7894b67f-8bzq2   172.16.221.135   Running   w1-k8s
echo-hname-7894b67f-dzhd6   172.16.103.136   Running   w2-k8s
echo-hname-7894b67f-qd2f6   172.16.221.141   Running   w1-k8s
```

w1-k8s node가 새로 생성되었다.


4. `kubectl get nodes`를 실행해 drain 명령이 수행된 w3-k8s 노드의 상태를 확인합니다.
 cordon을 실행했을 때처럼 w3-k8s는 SchedulingDisabled 상태입니다.

```
[root@m-k8s ~]# kubectl get nodes
NAME     STATUS                     ROLES    AGE     VERSION
m-k8s    Ready                      master   3d23h   v1.18.4
w1-k8s   Ready                      <none>   3d23h   v1.18.4
w2-k8s   Ready                      <none>   3d23h   v1.18.4
w3-k8s   Ready,SchedulingDisabled   <none>   3d23h   v1.18.4
```

5. 유지보수가 끝났다고 가정하고 w3-k8s에 uncordon 명령을 실행해 스케줄을 받을 수 있는 상태로 복귀시킵니다
`kubectl uncordon w3-k8s`
```
[root@m-k8s ~]# kubectl uncordon w3-k8s
node/w3-k8s uncordoned
```

6. 다시 노드 상태를 확인합니다.
`kubectl get nodes`
```
NAME     STATUS   ROLES    AGE     VERSION
m-k8s    Ready    master   3d23h   v1.18.4
w1-k8s   Ready    <none>   3d23h   v1.18.4
w2-k8s   Ready    <none>   3d23h   v1.18.4
w3-k8s   Ready    <none>   3d23h   v1.18.4
```

7. 다음 진행을 위해 배포한 echo-hname을 삭제합니다.

```
[root@m-k8s ~]# kubectl delete -f ~/_Book_k8sInfra/ch3/3.2.8/echo-hname.yaml
deployment.apps "echo-hname" deleted
```

8. `kubectl get pods`로 배포된 파드가 없음을 확인합니다.
```
[root@m-k8s ~]# kubectl get pods
No resources found in default namespace.
```

## 파드 업데이트하고 복구하기

### 파드 업데이트하기
1. 다음 명령으로 컨테이너 버전 업데이트를 테스트하기 위한 파드를 배포합니다.
   
여기서 --record는 매우 중요한 옵션으로, 배포한 정보의 히스토리를 기록합니다.

`kubectl apply -f ~/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record`


2. record 옵션으로 기록된 히스토리는 rollout history 명령을 실행해 확인

```
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
```

3. 배포한 파드의 정보를 확인합니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`

```
NAME                             IP               STATUS    NODE
rollout-nginx-64dd56c7b5-fffcf   172.16.221.142   Running   w1-k8s
rollout-nginx-64dd56c7b5-lfv46   172.16.132.9     Running   w3-k8s
rollout-nginx-64dd56c7b5-spzxt   172.16.103.142   Running   w2-k8s
```

4. 배포된 파드에 속해 있는 nginx 컨테이너 버전을 curl -I(헤더 정보만 보여주는 옵션) 명령으로 확인합니다.
`curl -I --silent 172.16.221.142 | grep Server`
```
[root@m-k8s ~]# curl -I --silent 172.16.221.142 | grep Server
Server: nginx/1.15.12
```

5. set image 명령으로 파드의 nginx 컨테이너 버전을 1.16.0으로 업데이트합니다. 이번에도 --record를 명령에 포함해 실행한 명령을 기록합니다.
`kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record`

6. 업데이트한 후에 파드의 상태를 확인합니다.

```
NAME                             IP               STATUS    NODE
rollout-nginx-8566d57f75-5pc9v   172.16.132.10    Running   w3-k8s
rollout-nginx-8566d57f75-dpr8k   172.16.103.143   Running   w2-k8s
rollout-nginx-8566d57f75-swg8w   172.16.221.143   Running   w1-k8s
```
결과를 보니 파드들의 이름과 IP가 변경됐습니다.

WHY??

파드는 언제라도 지우고 다시 만들 수 있다.

파드에 속한 nginx 컨테이너를 업데이트하는 가장 쉬운 방법 -> 파드를 관리하는 replicas의 수를 줄이고 늘려 파드를 새로 생성하는 것

이때 시스템의 영향을 최소화하기 위해 replicas에 속한 파드를 모두 한 번에 지우는 것이 아니라 파드를 하나씩 순차적으로 지우고 생성

이때 파드 수가 많으면 하나씩이 아니라 다수의 파드가 업데이트


7. nginx 컨테이너가 1.16.0으로 모두 업데이트되면 Deployment의 상태를 확인합니다.
`kubectl rollout status deployment rollout-nginx`
```
[root@m-k8s ~]# kubectl rollout status deployment rollout-nginx
deployment "rollout-nginx" successfully rolled out
```

8. rollout history 명령을 실행해 rollout-nginx에 적용된 명령들을 확인합니다.
`kubectl rollout history deployment rollout-nginx`
```
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
2         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
```

9. curl –I 명령으로 업데이트(1.16.0)가 제대로 이루어졌는지도 확인합니다.
`curl -I --silent 172.16.132.10 | grep Server`

```
[root@m-k8s ~]# curl -I --silent 172.16.132.10 | grep Server
Server: nginx/1.16.0
```

### 업데이트 실패 시 파드 복구하기
1. set image 명령으로 nginx 컨테이너 버전을 의도(1.17.2)와 다르게 1.17.23으로 입력합니다.
`kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record`

2. 하지만 이번에는 한참을 쉬고 돌아와도 파드가 삭제되지 않고 pending(대기 중) 상태에서 넘어가지 않습니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`

```
NAME                             IP               STATUS    NODE
rollout-nginx-8566d57f75-5pc9v   172.16.132.10    Running   w3-k8s
rollout-nginx-8566d57f75-dpr8k   172.16.103.143   Running   w2-k8s
rollout-nginx-8566d57f75-swg8w   172.16.221.143   Running   w1-k8s
rollout-nginx-856f4c79c9-7f2tx   172.16.132.11    Pending   w3-k8s
```

3. 어떤 문제인지를 확인하기 위해 `kubectl rollout status deployment rollout-nginx`를 실행합니다.

```
Waiting for deployment "rollout-nginx" rollout to finish: 1 out of 3 new replicas have been updated...
```

새로운 replicas는 생성했으나(new replicas have been updated) 디플로이먼트를 배포하는 단계에서 대기 중(Waiting)으로 더 이상 진행되지 않은 것을 확인할 수 있습니다.

4. Deployment를 생성하려고 여러 번 시도했지만, 끝내 생성되지 않았다는 메시지가 출력됩니다.

```
error: deployment "rollout-nginx" exceeded its progress deadline
```

5. describe 명령으로 문제점을 좀 더 자세히 살펴봅시다. 이 명령은 쿠버네티스의 상태를 살펴볼 때 유용합니다.
`kubectl describe deployment rollout-nginx`

`NewReplicaSet:   rollout-nginx-856f4c79c9 (1/1 replicas created)`

describe 명령으로 확인하니 replicas가 새로 생성되는 과정에서 멈춰 있습니다.

그 이유는 1.17.23 버전의 nginx 컨테이너가 없기 때문

실제로 배포할 때 이런 실수를 할 가능성이 충분히 있습니다.

이를 방지하고자 업데이트할 때 rollout을 사용하고 --record로 기록하는 것입니다.


6. 문제를 확인했으니 정상적인 상태로 복구하는 방법을 살펴보겠습니다.

업데이트할 때 사용했던 명령들을 rollout history로 확인합니다.
`kubectl rollout history deployment rollout-nginx`

```
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
2         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
3         kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true
```

7. rollout undo로 명령 실행을 취소해 마지막 단계(revision 3)에서 전 단계(revision 2)로 상태를 되돌립니다.
`kubectl rollout undo deployment rollout-nginx`


8. 파드 상태를 다시 확인합니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`

```
NAME                             IP               STATUS    NODE
rollout-nginx-8566d57f75-5pc9v   172.16.132.10    Running   w3-k8s
rollout-nginx-8566d57f75-dpr8k   172.16.103.143   Running   w2-k8s
rollout-nginx-8566d57f75-swg8w   172.16.221.143   Running   w1-k8s
```

9. rollout history로 실행된 명령을 확인합니다.
`kubectl rollout history deployment rollout-nginx`

```
[root@m-k8s ~]# kubectl rollout history deployment rollout-nginx
deployment.apps/rollout-nginx
REVISION  CHANGE-CAUSE
1         kubectl apply --filename=/root/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml --record=true
3         kubectl set image deployment rollout-nginx nginx=nginx:1.17.23 --record=true
4         kubectl set image deployment rollout-nginx nginx=nginx:1.16.0 --record=true
```

revision 4가 추가되고 revision 2가 삭제됐습니다. 현재 상태를 revision 2로 되돌렸기 때문에 revision 2는 삭제되고 가장 최근 상태는 revision 4가 됩니다.


10.   배포된 컨테이너의 nginx 버전을 curl -I로 확인합니다.
`curl -I --silent 172.16.132.10 | grep Server`
```
[root@m-k8s ~]# curl -I --silent 172.16.132.10 | grep Server
Server: nginx/1.16.0
```

11.   rollout status 명령으로 변경이 정상적으로 적용됐는지 확인합니다.
`kubectl rollout status deployment rollout-nginx`

```
[root@m-k8s ~]#  kubectl rollout status deployment rollout-nginx
deployment "rollout-nginx" successfully rolled out
```

12.   describe로 현재 디플로이먼트 상태도 세부적으로 점검하고 넘어갑니다.
`kubectl describe deployment rollout-nginx`

`NewReplicaSet:   rollout-nginx-8566d57f75 (3/3 replicas created)`

### 특정 시점으로 파드 복구하기

1. 처음 상태인 revision 1으로 돌아가 봅시다.
`kubectl rollout undo deployment rollout-nginx --to-revision=1`

```
[root@m-k8s ~]# kubectl rollout undo deployment rollout-nginx --to-revision=1
deployment.apps/rollout-nginx rolled back
```

2. 새로 생성된 파드들의 IP를 확인합니다.
`kubectl get pods -o=custom-columns=NAME:.metadata.name,IP:.status.podIP,STATUS:.status.phase,NODE:.spec.nodeName`
```
NAME                             IP               STATUS    NODE
rollout-nginx-64dd56c7b5-5zv8f   172.16.103.144   Running   w2-k8s
rollout-nginx-64dd56c7b5-lptvl   172.16.221.144   Running   w1-k8s
rollout-nginx-64dd56c7b5-qxm6g   172.16.132.12    Running   w3-k8s
```

3. curl -I로 nginx 컨테이너의 버전을 확인합니다. 1.15.12 버전이므로 처음 상태로 복구됐습니다.

`curl -I --silent 172.16.103.144 | grep Server`
```
[root@m-k8s ~]# curl -I --silent 172.16.103.144 | grep Server
Server: nginx/1.15.12
```

4. 다음 단계 진행을 위해 배포한 rollout-nginx 디플로이먼트를 삭제(delete)합니다.
```
[root@m-k8s ~]# kubectl delete -f ~/_Book_k8sInfra/ch3/3.2.10/rollout-nginx.yaml
deployment.apps "rollout-nginx" deleted
```

5. 배포된 파드가 없는지 확인합니다.
`kubectl get pods`
```
[root@m-k8s ~]# kubectl get pods
No resources found in default namespace.
```